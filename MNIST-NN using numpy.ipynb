{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L - Layer Neural Network\n",
    "I will be making a neural network that has an adjustable number of layers and neurons. The activation function per layer can also be changed from either relu, sigmoid or tanh. I will be using a hte MNIST dataset and predict whether the image is the number one (1) or it is a different digit in which I will use a zero (0). I got the MNIST dataset from kaggle so, it might no longer be the original. The main point of this exercise is to showcase my knowledge of Neural Networks by coding it without the use of any machine learning packages. I learned how to do this from Andrew NG's deep learning coursera class so, there will be similarities from his lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1908,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1909,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST = pd.read_csv('MNIST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1910,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         0  \n",
       "2         0         0         0         0         0  \n",
       "3         0         0         0         0         0  \n",
       "4         0         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 1910,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1911,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 785)"
      ]
     },
     "execution_count": 1911,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1912,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 1912,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Samples\n",
    "#### The Number One"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1913,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28.0"
      ]
     },
     "execution_count": 1913,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1914,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x24294d7e828>"
      ]
     },
     "execution_count": 1914,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD8CAYAAAAfZJO2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvu7QONwqgS8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24294c8eba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit_num = 0\n",
    "t = MNIST.drop('label',1)\n",
    "grid_data = t.iloc[digit_num].as_matrix().reshape(28,28)\n",
    "plt.imshow(grid_data, interpolation = \"none\", cmap = \"Greys\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other Numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1915,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x24294c79d68>"
      ]
     },
     "execution_count": 1915,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD8CAYAAAAfZJO2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWdJcxMwsaS5iZpY0FzEzS5qLmJkl7f8Ab13yog/S4NIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24295e3c9e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "digit_num = 7001\n",
    "grid_data = t.iloc[digit_num].as_matrix().reshape(28,28)\n",
    "plt.imshow(grid_data, interpolation = \"none\", cmap = \"Greys\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1916,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_zero(data):\n",
    "    if data['label'] != 1:\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1917,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST['label'] = MNIST.apply(convert_to_zero,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the dataset into equal parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1918,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9368"
      ]
     },
     "execution_count": 1918,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "4684*2 #Number of 1's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1919,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ones_only(data):\n",
    "    if data['label'] == 1:\n",
    "        label1 = 1\n",
    "    else:\n",
    "        label1 = np.random.uniform()\n",
    "    return label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1920,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST['label1'] = MNIST.apply(ones_only,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1921,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>label1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.311740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.290157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.236799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      0       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8    ...     pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0    ...            0         0         0         0         0   \n",
       "1       0    ...            0         0         0         0         0   \n",
       "2       0    ...            0         0         0         0         0   \n",
       "3       0    ...            0         0         0         0         0   \n",
       "4       0    ...            0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783    label1  \n",
       "0         0         0         0         0  1.000000  \n",
       "1         0         0         0         0  0.311740  \n",
       "2         0         0         0         0  1.000000  \n",
       "3         0         0         0         0  0.290157  \n",
       "4         0         0         0         0  0.236799  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 1921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1922,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST = MNIST.sort_values(by='label1',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1923,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST = MNIST[:9368]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1924,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MNIST = MNIST.drop(['label1'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1925,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "0    4684\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 1925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST.label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividing the data into train, dev and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1926,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9368, 785)"
      ]
     },
     "execution_count": 1926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10% will be allocated for the dev set and another 10% for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1927,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "936.8000000000001"
      ]
     },
     "execution_count": 1927,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9368*.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1928,
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST['permutation'] = np.random.permutation(9368)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the one's and zero's are equal if not manually divide it into equal parts. I will be using the first 10% of the data for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1929,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    497\n",
       "0    439\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 1929,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST[MNIST.permutation<936].label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1930,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = MNIST[MNIST.permutation<936]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be using the last 10% of the data for the dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1931,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8432"
      ]
     },
     "execution_count": 1931,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "9368 - 936"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1932,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    472\n",
       "0    463\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 1932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST[MNIST.permutation>8432].label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1933,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev = MNIST[MNIST.permutation>8432]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will check if the leftover data is balanced and if they are I will assign them into the training set and if not I will manually balance them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1934,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3781\n",
       "1    3714\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 1934,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MNIST[(MNIST.permutation<8432) & (MNIST.permutation>936)].label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1935,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = MNIST[(MNIST.permutation<8432) & (MNIST.permutation>936)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1936,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>permutation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24417</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24443</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24448</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24460</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24467</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3820</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 786 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "24417      1       0       0       0       0       0       0       0       0   \n",
       "24443      1       0       0       0       0       0       0       0       0   \n",
       "24448      1       0       0       0       0       0       0       0       0   \n",
       "24460      1       0       0       0       0       0       0       0       0   \n",
       "24467      1       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8     ...       pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "24417       0     ...              0         0         0         0         0   \n",
       "24443       0     ...              0         0         0         0         0   \n",
       "24448       0     ...              0         0         0         0         0   \n",
       "24460       0     ...              0         0         0         0         0   \n",
       "24467       0     ...              0         0         0         0         0   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  permutation  \n",
       "24417         0         0         0         0         2474  \n",
       "24443         0         0         0         0         3909  \n",
       "24448         0         0         0         0         1612  \n",
       "24460         0         0         0         0         6883  \n",
       "24467         0         0         0         0         3820  \n",
       "\n",
       "[5 rows x 786 columns]"
      ]
     },
     "execution_count": 1936,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1937,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop('label', 1)\n",
    "train_x = train_x.drop('permutation', 1)\n",
    "train_x = train_x.T\n",
    "train_y = train['label']\n",
    "train_y = train_y.values.reshape((1,train_y.shape[0]))\n",
    "\n",
    "test_x = test.drop('label', 1)\n",
    "test_x = test_x.drop('permutation', 1)\n",
    "test_x = test_x.T\n",
    "test_y = test['label']\n",
    "test_y = test_y.values.reshape((1,test_y.shape[0]))\n",
    "\n",
    "dev_x = dev.drop('label', 1)\n",
    "dev_x = dev_x.drop('permutation', 1)\n",
    "dev_x = dev_x.T\n",
    "dev_y = dev['label']\n",
    "dev_y = dev_y.values.reshape((1,dev_y.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# L-layer Neural Network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize_parameters\n",
    "This is the method that initializes the parameter W for weights and set up the architecture of the neural network. It uses random numbers between Zero and One for initialization. Initializing the bias into a random number almost makes no difference so, I wont be initializing into a random number but just zeros. There are a research that suggest different methods of initializing the weights however, it is not in the scope of this exercise. The list layer_dims will dictate how many neurons there are based on each digit on the list and each digit on the list represents a layer. \n",
    "\n",
    "Ex. layer_dims = [5,3,1], this is a neural network with 5 neurons in the first layer, 3 neurons in the second layer and 1 node in the last layer.\n",
    "\n",
    " \n",
    "    Arguments:\n",
    "    layer_dims -- python array (list) containing the dimensions of each layer in our network\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters \"W1\", \"b1\", ..., \"WL\", \"bL\":\n",
    "                    Wl -- weight matrix of shape (layer_dims[l], layer_dims[l-1])\n",
    "                    bl -- bias vector of shape (layer_dims[l], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1938,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(layer_dims):\n",
    "    \n",
    "    parameters = {}\n",
    "    L = len(layer_dims)           \n",
    "\n",
    "    for l in range(1, L):\n",
    "        \n",
    "        parameters['W' + str(l)] = np.random.randn(layer_dims[l],layer_dims[l-1])*0.01\n",
    "        parameters['b' + str(l)] = np.zeros((layer_dims[l],1))\n",
    "      \n",
    "        assert(parameters['W' + str(l)].shape == (layer_dims[l], layer_dims[l-1]))\n",
    "        assert(parameters['b' + str(l)].shape == (layer_dims[l], 1))\n",
    "\n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear_forward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is in the forward propagation phase. It performs the dot product of the previous layer's output with the current layer's weights.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python dictionary containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1939,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "\n",
    "    Z = np.dot(W,A)+b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acitivation Funtions \n",
    "Activation functions are the building blocks of our Neural Network. Each activation function represents the neuron of our brain. It performs the most basic predictions. Alone, they are weak however once they are linked together they have limitless potential. There are a number of Activations out there but I will be only using the most basic ones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relu Function\n",
    "<p>The Relu Function is a piecewise function that basically gets rid of negative numbers and replaces them with a 0. </p>\n",
    "\n",
    "\n",
    "if X > 0 then X \n",
    "\n",
    "\n",
    "if X < 0 then 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1940,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    r = z * (z > 0)\n",
    "    return r,z "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid Function\n",
    "The Sigmoid Function has a Range(Y) from 0 to 1 and has Domain(X) of negative infinity to positive infinity. It's purpose is that no matter how big or how small you a number you give it, it will output a number between 0 and 1.\n",
    "\n",
    "\n",
    "Sigmoid(x) = 1/(1+e^-x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1941,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s,z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanh Function\n",
    "This is similar to the sigmoid function however its range is from -1 to 1. So, we dont have to worry as much for the weights to blow up. \n",
    "\n",
    "Tanh = (2/(1+e^-x)) - 1\n",
    "     = 2Sigmoid(2x) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1942,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    t = (2/(1+np.exp(-z))) - 1\n",
    "    return t,z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear_activation_forward\n",
    "Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python dictionary containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1943,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "    if activation == \"sigmoid\":\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        A, activation_cache = relu(Z)\n",
    "        \n",
    "    elif activation == \"tanh\":\n",
    "        A, activation_cache = tanh(Z)\n",
    "    \n",
    "    else:\n",
    "        print(\"Error in Activation\")\n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L_model_forward\n",
    "This is where we bring the whole forward propagation together. This loops the linear_activation_forard method into all the layers. In the final layer we apply the sigmoid function because we want the output to be between 1 and 0. For all the other layers we will be using the relu.\n",
    "\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_relu_forward() (there are L-1 of them, indexed from 0 to L-2)\n",
    "                the cache of linear_sigmoid_forward() (there is one, indexed L-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1944,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters,activation):\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2             \n",
    "    \n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev,parameters['W' + str(l)], parameters['b' + str(l)], activation=activation[l])\n",
    "        caches.append(cache)\n",
    "        \n",
    "    AL, cache = linear_activation_forward(A,parameters['W' + str(L)], parameters['b' + str(L)], activation='sigmoid')\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "    assert (L == len(activation))\n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compute_cost\n",
    "The cost function is the function that we will be minimizing using gradient decent. The cost function measures the accuracy of our model. For this exercise we will be using the cross entropy cost for our cost function.\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1945,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = -(1/m)*np.sum((Y*np.log(AL))+((1-Y)*np.log(1-AL)))\n",
    "    cost = np.squeeze(cost)   \n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Propagation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### relu_backward\n",
    "Implement the backward propagation for a single RELU unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1946,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dA, cache):\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) \n",
    "    dZ[Z <= 0] = 0 \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid_backward\n",
    "Implement the backward propagation for a single SIGMOID unit.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- \\'Z\\' where we store for computing backward propagation efficiently\n",
    "    \n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1947,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_backward(dA, cache):\n",
    "\n",
    "    Z = cache\n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tanh_backward\n",
    "Implement the backward probagaytion for a single TanH unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- \\'Z\\' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1948,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tanh_backward(dA, cache):\n",
    "    \n",
    "    Z = cache\n",
    "    s = np.tanh(-Z)#(2/(1+np.exp(-Z))) - 1\n",
    "    dZ = 1 - (s**2)\n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear_backward\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1949,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    dW = (1/m)*np.dot(dZ,A_prev.T)\n",
    "    db = (1/m)*np.sum(dZ,axis=1, keepdims=True)\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### linear_activation_backward\n",
    "Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1950,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db =  linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db =  linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"tanh\":\n",
    "        dZ = tanh_backward(dA,activation_cache)\n",
    "        dA_prev, dW, db =  linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model_backward\n",
    "Implement the backward propagation for the [LINEAR->RELU] * (L-1) -> LINEAR -> SIGMOID group\n",
    "    \n",
    "    Arguments:\n",
    "    AL -- probability vector, output of the forward propagation (L_model_forward())\n",
    "    Y -- true \"label\" vector (containing 0 if non-cat, 1 if cat)\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() with \"relu\" (it's caches[l], for l in range(L-1) i.e l = 0...L-2)\n",
    "                the cache of linear_activation_forward() with \"sigmoid\" (it's caches[L-1])\n",
    "    \n",
    "    Returns:\n",
    "    grads -- A dictionary with the gradients\n",
    "             grads[\"dA\" + str(l)] = ... \n",
    "             grads[\"dW\" + str(l)] = ...\n",
    "             grads[\"db\" + str(l)] = ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1951,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_backward(AL, Y, caches,activation):\n",
    "\n",
    "    grads = {}\n",
    "    L = len(caches) \n",
    "    m = AL.shape[1]\n",
    "    Y = Y.reshape(AL.shape)\n",
    "    \n",
    "    dAL = - (np.divide(Y, AL) - np.divide(1 - Y, 1 - AL)) \n",
    "    \n",
    "    current_cache = caches[L-1]\n",
    "    grads[\"dA\" + str(L)], grads[\"dW\" + str(L)], grads[\"db\" + str(L)] = linear_activation_backward(dAL, current_cache, activation = 'sigmoid')\n",
    "\n",
    "    for l in reversed(range(L-1)):\n",
    "        current_cache = caches[l]\n",
    "        dA_prev_temp, dW_temp, db_temp = linear_activation_backward(grads[\"dA\" + str(l + 2)], current_cache, activation = activation[l])\n",
    "        grads[\"dA\" + str(l + 1)] = dA_prev_temp\n",
    "        grads[\"dW\" + str(l + 1)] = dW_temp\n",
    "        grads[\"db\" + str(l + 1)] = db_temp\n",
    "\n",
    "    return grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### update_parameters\n",
    "We will take what the algorithm has learned from gradient descent and update the parameters\n",
    "\n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1952,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    L = len(parameters) // 2 \n",
    "    \n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters['W' + str(l+1)] - learning_rate* grads[\"dW\" + str(l + 1)] \n",
    "        parameters[\"b\" + str(l+1)] = parameters['b' + str(l+1)] - learning_rate* grads[\"db\" + str(l + 1)] \n",
    "        \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L_layer_model\n",
    "Putting the whole model together. Implements a L-layer neural network: [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (number of examples, num_px * num_px * 3)\n",
    "    Y -- true \"label\" vector (containing 0 if cat, 1 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- list containing the input size and each layer size, of length (number of layers + 1).\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    print_cost -- if True, it prints the cost every 100 steps\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- parameters learnt by the model. They can then be used to predict.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1953,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def L_layer_model(X, Y, layers_dims,activation, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):#lr was 0.009\n",
    "\n",
    "    costs = []                         \n",
    "    \n",
    "    parameters = initialize_parameters(layers_dims)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        AL, caches = L_model_forward(X, parameters,activation)\n",
    "        cost = compute_cost(AL, Y)\n",
    "        grads = model_backward(AL, Y, caches,activation)\n",
    "        parameters =  update_parameters(parameters, grads, learning_rate)\n",
    "\n",
    "        if print_cost and i % 10 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "        if print_cost and i % 10 == 0:\n",
    "            costs.append(cost)\n",
    "            \n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict\n",
    "    This function is used to predict the results of our model.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1954,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(X, y, parameters,activation):\n",
    "\n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 \n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    probas, caches = L_model_forward(X, parameters,activation)\n",
    "    \n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        \n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "\n",
    "    print(\"Number of Ones = \"+str(np.sum(p)))\n",
    "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
    "    assert (n == len(activation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a simple model to start that we can easily tweak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1955,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers_dims = [train_x.shape[0],12,7, 1]\n",
    "activation = [\"sigmoid\",\"relu\",\"tanh\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1956,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.692414\n",
      "Cost after iteration 10: 0.691262\n",
      "Cost after iteration 20: 0.689016\n",
      "Cost after iteration 30: 0.684478\n",
      "Cost after iteration 40: 0.676106\n",
      "Cost after iteration 50: 0.662631\n",
      "Cost after iteration 60: 0.645388\n",
      "Cost after iteration 70: 0.629639\n",
      "Cost after iteration 80: 0.612987\n",
      "Cost after iteration 90: 0.595262\n",
      "Cost after iteration 100: 0.576206\n",
      "Cost after iteration 110: 0.548830\n",
      "Cost after iteration 120: 0.522127\n",
      "Cost after iteration 130: 0.496882\n",
      "Cost after iteration 140: 0.473557\n",
      "Cost after iteration 150: 0.452107\n",
      "Cost after iteration 160: 0.430224\n",
      "Cost after iteration 170: 0.414534\n",
      "Cost after iteration 180: 0.405106\n",
      "Cost after iteration 190: 0.400777\n",
      "Cost after iteration 200: 0.392853\n",
      "Cost after iteration 210: 0.396307\n",
      "Cost after iteration 220: 0.379641\n",
      "Cost after iteration 230: 0.376741\n",
      "Cost after iteration 240: 0.339502\n",
      "Cost after iteration 250: 0.239166\n",
      "Cost after iteration 260: 0.304346\n",
      "Cost after iteration 270: 0.307564\n",
      "Cost after iteration 280: 0.206210\n",
      "Cost after iteration 290: 0.230662\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24294e6f6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 300, print_cost = True,learning_rate=.01,activation = activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1957,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ones = 3036.0\n",
      "Accuracy: 0.905537024683\n"
     ]
    }
   ],
   "source": [
    "predict(train_x, train_y, parameters,activation)#0.999066044029"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1958,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ones = 414.0\n",
      "Accuracy: 0.909188034188\n"
     ]
    }
   ],
   "source": [
    "predict(test_x, test_y, parameters,activation)#0.987179487179"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Deeper Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1965,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers_dims = [train_x.shape[0],40,35,30,25,20,15,10,5, 1]\n",
    "activation = [\"relu\",\"relu\",\"relu\",\"relu\",\"relu\",\"relu\",\"relu\",\"relu\",\"relu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1966,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "Cost after iteration 10: 0.693107\n",
      "Cost after iteration 20: 0.693107\n",
      "Cost after iteration 30: 0.693107\n",
      "Cost after iteration 40: 0.693107\n",
      "Cost after iteration 50: 0.693107\n",
      "Cost after iteration 60: 0.693107\n",
      "Cost after iteration 70: 0.693107\n",
      "Cost after iteration 80: 0.693107\n",
      "Cost after iteration 90: 0.693107\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAEWCAYAAADGjIh1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKJmZWcX4v1xF6L21U54hAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24294af4f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 100, print_cost = True,learning_rate=1,activation=activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1968,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ones = 0.0\n",
      "Accuracy: 0.504469646431\n"
     ]
    }
   ],
   "source": [
    "predict(train_x, train_y, parameters,activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1969,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ones = 0.0\n",
      "Accuracy: 0.469017094017\n"
     ]
    }
   ],
   "source": [
    "predict(test_x, test_y, parameters,activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is just far too complex for our very simple problem furthermore, it is not learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1970,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layers_dims = [train_x.shape[0],10,4, 1]\n",
    "activation = [\"tanh\",\"relu\",\"relu\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1971,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.692847\n",
      "Cost after iteration 10: 0.690583\n",
      "Cost after iteration 20: 0.674068\n",
      "Cost after iteration 30: 0.351081\n",
      "Cost after iteration 40: 0.090660\n",
      "Cost after iteration 50: 0.072699\n",
      "Cost after iteration 60: 0.066482\n",
      "Cost after iteration 70: 0.062861\n",
      "Cost after iteration 80: 0.060194\n",
      "Cost after iteration 90: 0.058033\n",
      "Cost after iteration 100: 0.056138\n",
      "Cost after iteration 110: 0.054404\n",
      "Cost after iteration 120: 0.052871\n",
      "Cost after iteration 130: 0.051480\n",
      "Cost after iteration 140: 0.050214\n",
      "Cost after iteration 150: 0.049046\n",
      "Cost after iteration 160: 0.047986\n",
      "Cost after iteration 170: 0.047008\n",
      "Cost after iteration 180: 0.046093\n",
      "Cost after iteration 190: 0.045215\n",
      "Cost after iteration 200: 0.044381\n",
      "Cost after iteration 210: 0.043587\n",
      "Cost after iteration 220: 0.042821\n",
      "Cost after iteration 230: 0.042070\n",
      "Cost after iteration 240: 0.041335\n",
      "Cost after iteration 250: 0.040616\n",
      "Cost after iteration 260: 0.039913\n",
      "Cost after iteration 270: 0.039209\n",
      "Cost after iteration 280: 0.038474\n",
      "Cost after iteration 290: 0.037776\n",
      "Cost after iteration 300: 0.037091\n",
      "Cost after iteration 310: 0.036421\n",
      "Cost after iteration 320: 0.035765\n",
      "Cost after iteration 330: 0.035111\n",
      "Cost after iteration 340: 0.034474\n",
      "Cost after iteration 350: 0.033854\n",
      "Cost after iteration 360: 0.033286\n",
      "Cost after iteration 370: 0.032888\n",
      "Cost after iteration 380: 0.033310\n",
      "Cost after iteration 390: 0.035696\n",
      "Cost after iteration 400: 0.038317\n",
      "Cost after iteration 410: 0.031808\n",
      "Cost after iteration 420: 0.029784\n",
      "Cost after iteration 430: 0.028938\n",
      "Cost after iteration 440: 0.028324\n",
      "Cost after iteration 450: 0.028217\n",
      "Cost after iteration 460: 0.032004\n",
      "Cost after iteration 470: 0.115029\n",
      "Cost after iteration 480: 0.116632\n",
      "Cost after iteration 490: 0.055196\n",
      "Cost after iteration 500: 0.047017\n",
      "Cost after iteration 510: 0.043142\n",
      "Cost after iteration 520: 0.040401\n",
      "Cost after iteration 530: 0.037994\n",
      "Cost after iteration 540: 0.036196\n",
      "Cost after iteration 550: 0.034918\n",
      "Cost after iteration 560: 0.033756\n",
      "Cost after iteration 570: 0.032686\n",
      "Cost after iteration 580: 0.031618\n",
      "Cost after iteration 590: 0.030635\n",
      "Cost after iteration 600: 0.029646\n",
      "Cost after iteration 610: 0.028670\n",
      "Cost after iteration 620: 0.027624\n",
      "Cost after iteration 630: 0.026646\n",
      "Cost after iteration 640: 0.025768\n",
      "Cost after iteration 650: 0.024951\n",
      "Cost after iteration 660: 0.024169\n",
      "Cost after iteration 670: 0.023403\n",
      "Cost after iteration 680: 0.022676\n",
      "Cost after iteration 690: 0.021970\n",
      "Cost after iteration 700: 0.021299\n",
      "Cost after iteration 710: 0.020636\n",
      "Cost after iteration 720: 0.020019\n",
      "Cost after iteration 730: 0.019439\n",
      "Cost after iteration 740: 0.018891\n",
      "Cost after iteration 750: 0.018371\n",
      "Cost after iteration 760: 0.017875\n",
      "Cost after iteration 770: 0.017392\n",
      "Cost after iteration 780: 0.016902\n",
      "Cost after iteration 790: 0.016438\n",
      "Cost after iteration 800: 0.015991\n",
      "Cost after iteration 810: 0.015563\n",
      "Cost after iteration 820: 0.015156\n",
      "Cost after iteration 830: 0.014772\n",
      "Cost after iteration 840: 0.014420\n",
      "Cost after iteration 850: 0.014079\n",
      "Cost after iteration 860: 0.013750\n",
      "Cost after iteration 870: 0.013425\n",
      "Cost after iteration 880: 0.013092\n",
      "Cost after iteration 890: 0.012742\n",
      "Cost after iteration 900: 0.012405\n",
      "Cost after iteration 910: 0.012079\n",
      "Cost after iteration 920: 0.011753\n",
      "Cost after iteration 930: 0.011426\n",
      "Cost after iteration 940: 0.011082\n",
      "Cost after iteration 950: 0.010758\n",
      "Cost after iteration 960: 0.010450\n",
      "Cost after iteration 970: 0.010162\n",
      "Cost after iteration 980: 0.009881\n",
      "Cost after iteration 990: 0.009618\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x242949b1710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters = L_layer_model(train_x, train_y, layers_dims, num_iterations = 1000, print_cost = True,learning_rate=.01,activation=[\"relu\",\"relu\",\"relu\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1972,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ones = 3708.0\n",
      "Accuracy: 0.998132088059\n"
     ]
    }
   ],
   "source": [
    "predict(train_x, train_y, parameters,activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1973,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ones = 499.0\n",
      "Accuracy: 0.980769230769\n"
     ]
    }
   ],
   "source": [
    "predict(test_x, test_y, parameters,activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1974,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Ones = 472.0\n",
      "Accuracy: 0.985026737968\n"
     ]
    }
   ],
   "source": [
    "predict(dev_x, dev_y, parameters,activation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This gives us an accuracy of ~99%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
